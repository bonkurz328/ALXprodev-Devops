#!/bin/bash

# Base URL for Pokémon API
BASE_URL="https://pokeapi.co/api/v2/pokemon"

# Output directory and error file
OUTPUT_DIR="pokemon_data"
ERROR_FILE="errors.txt"

# Create output directory if it doesn't exist
mkdir -p "$OUTPUT_DIR"

# List of Pokémon with their IDs
declare -A POKEMON_IDS=(
  ["bulbasaur"]=1
  ["ivysaur"]=2
  ["venusaur"]=3
  ["charmander"]=4
  ["charmeleon"]=5
)

# Maximum number of concurrent processes
MAX_JOBS=3

# Function to fetch Pokémon data
fetch_pokemon() {
  local pokemon=$1
  local id=$2
  echo "Fetching data for $pokemon..."
  # Make API request
  curl -s -o "$OUTPUT_DIR/$pokemon.json" "${BASE_URL}/${id}/" -w "%{http_code}" | {
    read http_code
    if [ "$http_code" -eq 200 ] && [ -s "$OUTPUT_DIR/$pokemon.json" ]; then
      echo "Saved data to $OUTPUT_DIR/$pokemon.json ✅"
    else
      echo "Error: Failed to fetch data for $pokemon (HTTP $http_code)" >> "$ERROR_FILE"
      echo "Failed to fetch data for $pokemon ❌"
    fi
  }
  # Small delay to avoid overwhelming API
  sleep 0.2
}

# Export function for use in parallel
export -f fetch_pokemon
export BASE_URL OUTPUT_DIR ERROR_FILE

# Counter for active jobs
active_jobs=0

# Loop through Pokémon and run in parallel
for pokemon in "${!POKEMON_IDS[@]}"; do
  # Run fetch_pokemon in background
  fetch_pokemon "$pokemon" "${POKEMON_IDS[$pokemon]}" &
  ((active_jobs++))

  # If maximum jobs reached, wait for some to finish
  if [ "$active_jobs" -ge "$MAX_JOBS" ]; then
    wait -n  # Wait for any process to finish
    ((active_jobs--))
  fi
done

# Wait for all remaining background processes to complete
wait

# Check if all expected files were created
for pokemon in "${!POKEMON_IDS[@]}"; do
  if [ ! -s "$OUTPUT_DIR/$pokemon.json" ]; then
    echo "Error: Data file for $pokemon not created or empty" >> "$ERROR_FILE"
  fi
done

echo "All Pokémon data retrieval completed."
